{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cfadd7d-7bf4-4bd5-9693-48ccb4b8854b",
   "metadata": {},
   "source": [
    "1. Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24f99943-3c9d-419d-ad1a-e0a8cbfdac03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 生成 2023 年词云：Final Project/wordclouds/wordcloud_2023.png\n",
      "✅ 生成 2024 年词云：Final Project/wordclouds/wordcloud_2024.png\n",
      "✅ 生成 2021 年词云：Final Project/wordclouds/wordcloud_2021.png\n",
      "✅ 生成 2025 年词云：Final Project/wordclouds/wordcloud_2025.png\n",
      "✅ 生成 2022 年词云：Final Project/wordclouds/wordcloud_2022.png\n",
      "✅ 保存所有年份词频和颜色数据：Final Project/wordclouds/all_years_word_data.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import jieba\n",
    "import jieba.posseg\n",
    "import jieba.analyse\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# --------------------- 配置区 ---------------------\n",
    "REPORT_DIR = \"Final Project/beijing_gov_reports\"  # 存放政府工作报告 TXT 的目录\n",
    "OUTPUT_DIR = \"Final Project/wordclouds\"           # 词云输出目录\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# 停用词（过滤通用词，保留名词）\n",
    "STOPWORDS = set([\n",
    "    '的', '了', '在', '是', '有', '和', '就', '不', '人', '都', '一',\n",
    "    '上', '也', '很', '到', '说', '要', '去', '会', '着', '没有', '这',\n",
    "    '北京', '本市', '年', '月', '日', '表示', '强调', '指出', '提出',\n",
    "    '建设', '推进', '发展', '体系', '改革', '加强', '完善'\n",
    "])\n",
    "\n",
    "# 全局词汇-颜色映射（同词同色，不同词不同色）\n",
    "word_color_map = {}\n",
    "# 定义更丰富的基础配色，参考目标词云色彩风格，包含红、橙、黄、绿、蓝、紫等色系\n",
    "base_colors = [\n",
    "    '#C62828', '#EF6C00', '#FDD835', '#7CB342', '#1565C0', \n",
    "    '#6A1B9A', '#455A64', '#FF8A80', '#8E24AA', '#00ACC1'\n",
    "]\n",
    "\n",
    "# --------------------- 工具函数 ---------------------\n",
    "def read_report(file_path):\n",
    "    \"\"\"读取政府工作报告文本\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "def preprocess_text(text, year):\n",
    "    \"\"\"预处理文本：过滤非名词 + TF-IDF 提取特色词\"\"\"\n",
    "    # 1. 过滤非中文\n",
    "    text = re.sub(r'[^\\u4e00-\\u9fa5]', ' ', text)\n",
    "    \n",
    "    # 2. 分词：只保留名词（n）和专有名词（nr）\n",
    "    words = jieba.posseg.cut(text)\n",
    "    # 动态停用词（补充年份相关通用词）\n",
    "    dynamic_stopwords = STOPWORDS.union({str(year), f\"{year}年\"})\n",
    "    filtered_words = [\n",
    "        w.word for w in words \n",
    "        if w.word.strip() \n",
    "        and w.word not in dynamic_stopwords \n",
    "        and (w.flag.startswith('n') or w.flag == 'nr')  # 只保留名词\n",
    "    ]\n",
    "    \n",
    "    # 3. TF-IDF 提取年度特色名词（强化名词权重）\n",
    "    keywords = jieba.analyse.extract_tags(\n",
    "        ' '.join(filtered_words), \n",
    "        topK=200, \n",
    "        withWeight=True,\n",
    "        allowPOS=('n', 'nr')  # 强制保留名词\n",
    "    )\n",
    "    \n",
    "    # 4. 构造词频字典（用于词云：出现次数越多，字号越大）\n",
    "    word_freq = {}\n",
    "    for word, weight in keywords:\n",
    "        # 年度专属词权重翻倍\n",
    "        if str(year) in word:\n",
    "            weight *= 2  \n",
    "        # 转换为整数频次（避免浮点数问题）\n",
    "        word_freq[word] = int(weight * 1000)  # 放大倍数，让字号差异更明显\n",
    "    \n",
    "    return word_freq\n",
    "\n",
    "def generate_wordcloud(word_freq, year):\n",
    "    \"\"\"生成词云（同词同色、不同词不同色 + 英文题注 + 无掩码）\"\"\"\n",
    "    global word_color_map\n",
    "    \n",
    "    # 1. 同词同色、不同词不同色逻辑：确保相同词汇颜色一致，不同词汇颜色不同\n",
    "    def color_func(word, **kwargs):\n",
    "        if word not in word_color_map:\n",
    "            # 循环取色（保证不同词不同色，同词同色）\n",
    "            color_idx = len(word_color_map) % len(base_colors)\n",
    "            word_color_map[word] = base_colors[color_idx]\n",
    "        return word_color_map[word]\n",
    "    \n",
    "    # 2. 配置词云（无掩码，靠词频和词性突出重点）\n",
    "    wc = WordCloud(\n",
    "        font_path='/System/Library/Fonts/PingFang.ttc',  # macOS 字体\n",
    "        # font_path='C:/Windows/Fonts/simhei.ttf',       # Windows 字体\n",
    "        width=800, \n",
    "        height=600,\n",
    "        background_color='white',\n",
    "        color_func=color_func,\n",
    "        max_words=300,\n",
    "        stopwords=STOPWORDS,\n",
    "        prefer_horizontal=0.9  # 让名词更水平显示，提升可读性\n",
    "    ).generate_from_frequencies(word_freq)\n",
    "    \n",
    "    # 3. 保存词云 + 英文题注\n",
    "    output_path = os.path.join(OUTPUT_DIR, f'wordcloud_{year}.png')\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    # 英文题注：Year 202X Beijing Government Work Report Word Cloud\n",
    "    plt.title(f'Year {year} Beijing Government Work Report Word Cloud', \n",
    "              fontsize=16, fontfamily='Arial')\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✅ 生成 {year} 年词云：{output_path}\")\n",
    "\n",
    "def save_all_word_data(all_word_data):\n",
    "    \"\"\"保存所有年份的词频字典和颜色信息到一个JSON文件\"\"\"\n",
    "    output_path = os.path.join(OUTPUT_DIR, 'all_years_word_data.json')\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_word_data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"✅ 保存所有年份词频和颜色数据：{output_path}\")\n",
    "\n",
    "# --------------------- 主逻辑 ---------------------\n",
    "def main():\n",
    "    # 1. 获取报告文件\n",
    "    report_files = [\n",
    "        f for f in os.listdir(REPORT_DIR) \n",
    "        if f.endswith(\".txt\") and \"政府工作报告\" in f\n",
    "    ]\n",
    "    if not report_files:\n",
    "        print(f\"❌ 错误：{REPORT_DIR} 目录下无有效报告文件\")\n",
    "        return\n",
    "    \n",
    "    all_word_data = []\n",
    "    \n",
    "    # 2. 逐个生成词云并收集数据\n",
    "    for file in report_files:\n",
    "        # 提取年份\n",
    "        year_match = re.search(r'(\\d{4})', file)\n",
    "        if not year_match:\n",
    "            print(f\"❌ 跳过 {file}：无有效年份\")\n",
    "            continue\n",
    "        year = int(year_match.group(1))\n",
    "        \n",
    "        # 处理文本：生成词频字典（突出名词）\n",
    "        file_path = os.path.join(REPORT_DIR, file)\n",
    "        raw_text = read_report(file_path)\n",
    "        word_freq = preprocess_text(raw_text, year)\n",
    "        \n",
    "        # 生成词云\n",
    "        if word_freq:\n",
    "            generate_wordcloud(word_freq, year)\n",
    "            \n",
    "            # 收集当前年份的数据\n",
    "            year_data = {\n",
    "                'year': year,\n",
    "                'word_frequencies': word_freq,\n",
    "                'word_colors': {word: word_color_map.get(word) for word in word_freq}\n",
    "            }\n",
    "            all_word_data.append(year_data)\n",
    "        else:\n",
    "            print(f\"❌ 跳过 {file}：无有效名词\")\n",
    "    \n",
    "    # 3. 保存所有年份的数据到一个JSON文件\n",
    "    if all_word_data:\n",
    "        save_all_word_data(all_word_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d16f18-8976-4ef4-b70a-cb6cda773efc",
   "metadata": {},
   "source": [
    "2. Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c583bc2-bfb8-4e9c-83a6-4c7c30806634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 生成关键词热力图：charts/keyword_heatmap.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# --------------------- 配置区 ---------------------\n",
    "JSON_PATH = \"wordclouds/all_years_word_data.json\"  # JSON数据文件路径\n",
    "CHART_DIR = \"charts\"                              # 图表输出目录\n",
    "os.makedirs(CHART_DIR, exist_ok=True)\n",
    "\n",
    "# 中英文关键词映射（复用原有配置）\n",
    "keyword_translation = {\n",
    "    '全面': 'Comprehensive',\n",
    "    '高质量': 'High-Quality',\n",
    "    '国际': 'International',\n",
    "    '中心': 'Center',\n",
    "    '文化': 'Culture',\n",
    "    '科技': 'Technology',\n",
    "    '重点': 'Focus',\n",
    "    '着力': 'Effort',\n",
    "    '京津冀': 'Beijing-Tianjin-Hebei',\n",
    "    '机制': 'Mechanism',\n",
    "    '示范区': 'Demonstration Zone',\n",
    "    '产业': 'Industry',\n",
    "    '领域': 'Field',\n",
    "    '政府': 'Government',\n",
    "    '协同': 'Collaboration',\n",
    "    '行动计划': 'Action Plan',\n",
    "    '国家': 'National',\n",
    "    '养老': 'Pension',\n",
    "    '生态': 'Ecology',\n",
    "    '企业': 'Enterprise',\n",
    "    '数字': 'Digital',\n",
    "    '绿色': 'Green',\n",
    "    '整治': 'Renovation',\n",
    "    '规划': 'Planning',\n",
    "    '功能': 'Function',\n",
    "    '人民': 'People',\n",
    "    '全市': 'Citywide',\n",
    "    '水平': 'Level',\n",
    "    '农村': 'Rural',\n",
    "    '经济': 'Economy',\n",
    "    '政策': 'Policy',\n",
    "    '任务': 'Task',\n",
    "    '高水平': 'High-Level',\n",
    "    '战略': 'Strategy',\n",
    "    '群众': 'Masses',\n",
    "    '全国': 'National',\n",
    "    '专项': 'Special',\n",
    "    '疫情': 'Epidemic',\n",
    "    '民生': 'Livelihood',\n",
    "    '社会主义': 'Socialism',\n",
    "    '地区': 'Region',\n",
    "    '环境': 'Environment',\n",
    "    '乡村': 'Rural',\n",
    "    '时代': 'Era',\n",
    "    '特色': 'Characteristic',\n",
    "    '精神': 'Spirit',\n",
    "    '人才': 'Talent',\n",
    "    '基层': 'Grassroots',\n",
    "    '大力': 'Vigorously',\n",
    "    '智慧': 'Wisdom'\n",
    "}\n",
    "\n",
    "# --------------------- 热力图生成函数 ---------------------\n",
    "def generate_heatmap(all_year_data):\n",
    "    \"\"\"生成关键词热力图（带中英文标注、年份倾斜显示）\"\"\"\n",
    "    # 整理数据：取所有年份中出现过的Top50关键词\n",
    "    all_words = {}\n",
    "    for year, data in all_year_data.items():\n",
    "        for word, freq in data['word_freq'].items():\n",
    "            all_words[word] = all_words.get(word, 0) + freq\n",
    "    top_words = [w for w, _ in sorted(all_words.items(), key=lambda x: x[1], reverse=True)[:50]]\n",
    "    \n",
    "    # 构建年份-关键词矩阵\n",
    "    years = sorted(all_year_data.keys())\n",
    "    heatmap_data = []\n",
    "    for word in top_words:\n",
    "        row = [all_year_data[year]['word_freq'].get(word, 0) for year in years]\n",
    "        heatmap_data.append(row)\n",
    "    \n",
    "    # 绘图\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    # 字体配置（兼容不同系统）\n",
    "    try:\n",
    "        font = FontProperties(fname='/System/Library/Fonts/PingFang.ttc')  # macOS 字体\n",
    "    except:\n",
    "        font = FontProperties(fname='C:/Windows/Fonts/simhei.ttf')       # Windows 字体\n",
    "    \n",
    "    # 绘制热力图（暖色调表示频率高低）\n",
    "    im = plt.imshow(heatmap_data, cmap='YlOrRd')  \n",
    "    \n",
    "    # 坐标轴配置（中英文标注 + 年份倾斜）\n",
    "    plt.xticks(\n",
    "        range(len(years)), \n",
    "        [str(year) for year in years], \n",
    "        fontsize=10, \n",
    "        rotation=45,  # 年份倾斜45度避免重叠\n",
    "        ha='right', \n",
    "        fontfamily='Arial'\n",
    "    )\n",
    "    plt.yticks(\n",
    "        range(len(top_words)), \n",
    "        [f'{word} ({keyword_translation.get(word, word)})' for word in top_words], \n",
    "        fontproperties=font, \n",
    "        fontsize=8\n",
    "    )\n",
    "    \n",
    "    # 颜色条（表示频率刻度）\n",
    "    cbar = plt.colorbar(im)\n",
    "    cbar.set_label('Frequency (Scaled)', fontfamily='Arial')\n",
    "    \n",
    "    # 标题\n",
    "    plt.title('Keyword Frequency Heatmap Across Years', fontsize=16, fontfamily='Arial')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 保存图表\n",
    "    output_path = os.path.join(CHART_DIR, 'keyword_heatmap.png')\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✅ 生成关键词热力图：{output_path}\")\n",
    "\n",
    "# --------------------- 数据读取函数 ---------------------\n",
    "def load_data_from_json(json_path):\n",
    "    \"\"\"从JSON文件加载数据并转换为年份映射格式\"\"\"\n",
    "    if not os.path.exists(json_path):\n",
    "        print(f\"❌ 错误：JSON文件不存在 - {json_path}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            json_data = json.load(f)\n",
    "        \n",
    "        # 转换为 {年份: {'word_freq': {...}}} 格式\n",
    "        year_data = {}\n",
    "        for item in json_data:\n",
    "            year = item['year']\n",
    "            year_data[year] = {\n",
    "                'word_freq': item['word_frequencies']  # 对应JSON中的词频字段\n",
    "            }\n",
    "        return year_data\n",
    "    \n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"❌ 错误：JSON文件解析失败 - {json_path}\")\n",
    "        return None\n",
    "    except KeyError as e:\n",
    "        print(f\"❌ 错误：JSON文件格式不正确，缺少字段 {e}\")\n",
    "        return None\n",
    "\n",
    "# --------------------- 主逻辑 ---------------------\n",
    "def main():\n",
    "    # 从JSON文件加载数据\n",
    "    all_year_data = load_data_from_json(JSON_PATH)\n",
    "    if not all_year_data:\n",
    "        return\n",
    "    \n",
    "    # 生成热力图（至少2个年份才生成）\n",
    "    if len(all_year_data) >= 2:\n",
    "        generate_heatmap(all_year_data)\n",
    "    else:\n",
    "        print(\"❌ 年份数量不足，无法生成热力图（至少需要2个年份）\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7639ef7-0f7c-4a9f-8854-c5d113b9f24e",
   "metadata": {},
   "source": [
    "2. Grouped_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62a17562-849f-40e6-a85b-c91fed56cfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成汇总柱状图...\n",
      "✅ 生成汇总柱状图：charts/grouped_bar.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import json\n",
    "\n",
    "# --------------------- 配置区（修改路径为相对路径） ---------------------\n",
    "JSON_PATH = \"wordclouds/all_years_word_data.json\"  # JSON数据文件路径\n",
    "OUTPUT_DIR = \"wordclouds\"           # 词云输出目录（用于复用颜色映射）\n",
    "CHART_DIR = \"charts\"                # 图表输出目录\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(CHART_DIR, exist_ok=True)\n",
    "\n",
    "# 全局词汇-颜色映射（复用词云生成的颜色）\n",
    "word_color_map = {}\n",
    "# 基础配色（与原词云代码保持一致）\n",
    "base_colors = [\n",
    "    '#C62828', '#EF6C00', '#FDD835', '#7CB342', '#1565C0', \n",
    "    '#6A1B9A', '#455A64', '#FF8A80', '#8E24AA', '#00ACC1'\n",
    "]\n",
    "\n",
    "# 中英文关键词映射（用于图表标注）\n",
    "keyword_translation = {\n",
    "    '全面': 'Comprehensive',\n",
    "    '高质量': 'High-Quality',\n",
    "    '国际': 'International',\n",
    "    '中心': 'Center',\n",
    "    '文化': 'Culture',\n",
    "    '科技': 'Technology',\n",
    "    '重点': 'Focus',\n",
    "    '着力': 'Effort',\n",
    "    '京津冀': 'Beijing-Tianjin-Hebei',\n",
    "    '机制': 'Mechanism',\n",
    "    '示范区': 'Demonstration Zone',\n",
    "    '产业': 'Industry',\n",
    "    '领域': 'Field',\n",
    "    '政府': 'Government',\n",
    "    '协同': 'Collaboration',\n",
    "    '行动计划': 'Action Plan',\n",
    "    '国家': 'National',\n",
    "    '养老': 'Pension',\n",
    "    '生态': 'Ecology',\n",
    "    '企业': 'Enterprise',\n",
    "    '数字': 'Digital',\n",
    "    '绿色': 'Green',\n",
    "    '整治': 'Renovation',\n",
    "    '规划': 'Planning',\n",
    "    '功能': 'Function',\n",
    "    '人民': 'People',\n",
    "    '全市': 'Citywide',\n",
    "    '水平': 'Level',\n",
    "    '农村': 'Rural',\n",
    "    '经济': 'Economy',\n",
    "    '政策': 'Policy',\n",
    "    '任务': 'Task',\n",
    "    '高水平': 'High-Level',\n",
    "    '战略': 'Strategy',\n",
    "    '群众': 'Masses',\n",
    "    '全国': 'National',\n",
    "    '专项': 'Special',\n",
    "    '疫情': 'Epidemic',\n",
    "    '民生': 'Livelihood',\n",
    "    '社会主义': 'Socialism',\n",
    "    '地区': 'Region',\n",
    "    '环境': 'Environment',\n",
    "    '乡村': 'Rural',\n",
    "    '时代': 'Era',\n",
    "    '特色': 'Characteristic',\n",
    "    '精神': 'Spirit',\n",
    "    '人才': 'Talent',\n",
    "    '基层': 'Grassroots',\n",
    "    '大力': 'Vigorously',\n",
    "    '智慧': 'Wisdom'\n",
    "}\n",
    "\n",
    "# --------------------- 数据读取函数 ---------------------\n",
    "def load_data_from_json(json_path):\n",
    "    \"\"\"从JSON文件加载数据并重建颜色映射\"\"\"\n",
    "    if not os.path.exists(json_path):\n",
    "        print(f\"❌ 错误：JSON文件不存在 - {json_path}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            json_data = json.load(f)\n",
    "        \n",
    "        # 转换为 {年份: {'word_freq': {...}}} 格式，并重建颜色映射\n",
    "        year_data = {}\n",
    "        global word_color_map\n",
    "        word_color_map = {}  # 重置颜色映射\n",
    "        \n",
    "        for item in json_data:\n",
    "            year = item['year']\n",
    "            year_data[year] = {\n",
    "                'word_freq': item['word_frequencies']\n",
    "            }\n",
    "            # 从JSON中恢复颜色映射（确保与词云颜色一致）\n",
    "            for word, color in item['word_colors'].items():\n",
    "                if word not in word_color_map:\n",
    "                    word_color_map[word] = color\n",
    "        \n",
    "        return year_data\n",
    "    \n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"❌ 错误：JSON文件解析失败 - {json_path}\")\n",
    "        return None\n",
    "    except KeyError as e:\n",
    "        print(f\"❌ 错误：JSON文件格式不正确，缺少字段 {e}\")\n",
    "        return None\n",
    "\n",
    "# --------------------- 图表生成函数 ---------------------\n",
    "def generate_grouped_bar(all_year_data, top_n=15):\n",
    "    \"\"\"生成多年份分组柱状图（复用词云颜色 + 中文正确显示 + 数值标签）\"\"\"\n",
    "    print(\"生成汇总柱状图...\")\n",
    "    years = sorted(all_year_data.keys())\n",
    "    if len(years) < 2:\n",
    "        print(\"❌ 年份不足，无法生成分组柱状图\")\n",
    "        return\n",
    "    \n",
    "    # 提取各年份Top关键词并去重，按总频率排序\n",
    "    union_words = set()\n",
    "    for year in years:\n",
    "        top_words = [w for w, _ in sorted(\n",
    "            all_year_data[year]['word_freq'].items(), \n",
    "            key=lambda x: x[1], reverse=True\n",
    "        )[:top_n]]\n",
    "        union_words.update(top_words)\n",
    "    # 按跨年份总频率排序，取前N个关键词\n",
    "    union_words = sorted(union_words, key=lambda x: sum(\n",
    "        all_year_data[year]['word_freq'].get(x, 0) for year in years\n",
    "    ), reverse=True)[:top_n]\n",
    "    \n",
    "    # 构建数据\n",
    "    freq_data = {word: [all_year_data[year]['word_freq'].get(word, 0) for year in years] for word in union_words}\n",
    "    df = pd.DataFrame(freq_data, index=years)\n",
    "    \n",
    "    # 绘图：重点解决中文显示问题\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    # 指定中文字体路径（macOS/Windows 按需切换）\n",
    "    try:\n",
    "        font = FontProperties(fname='/System/Library/Fonts/PingFang.ttc')  # macOS\n",
    "    except:\n",
    "        font = FontProperties(fname='C:/Windows/Fonts/simhei.ttf')       # Windows\n",
    "    \n",
    "    # 复用词云颜色（与词云保持一致）\n",
    "    colors = [word_color_map.get(word, '#999999') for word in union_words]\n",
    "    ax = df.plot(kind='bar', width=0.8, color=colors, ax=plt.gca())\n",
    "    \n",
    "    # 添加数值标签（支持中文）\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        if height > 0:  # 只显示有值的标签\n",
    "            ax.annotate(f'{height}', \n",
    "                        xy=(p.get_x() + p.get_width()/2, height), \n",
    "                        xytext=(0, 3), \n",
    "                        textcoords='offset points',\n",
    "                        ha='center', va='bottom', fontproperties=font, fontsize=8)\n",
    "    \n",
    "    # 坐标轴与图例配置（中英文对照 + 中文正常显示）\n",
    "    plt.xticks(rotation=45, ha='right', fontfamily='Arial')  # X轴年份用Arial\n",
    "    plt.yticks(fontproperties=font)  # Y轴刻度用中文字体\n",
    "    ax.set_xlabel('Years', fontfamily='Arial', fontsize=12)\n",
    "    ax.set_ylabel('Frequency (Scaled)', fontfamily='Arial', fontsize=12)\n",
    "    ax.set_title('Keyword Frequency Comparison Across Years', fontfamily='Arial', fontsize=16)\n",
    "    \n",
    "    # 图例：中文关键词 + 英文翻译（放置在右侧避免重叠）\n",
    "    legend_labels = [f'{word} ({keyword_translation.get(word, word)})' for word in union_words]\n",
    "    ax.legend(title='Keywords', labels=legend_labels, \n",
    "              bbox_to_anchor=(1.05, 1), loc='upper left', \n",
    "              prop=font, fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 保存图表\n",
    "    output_path = os.path.join(CHART_DIR, 'grouped_bar.png')\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✅ 生成汇总柱状图：{output_path}\")\n",
    "\n",
    "# --------------------- 主逻辑 ---------------------\n",
    "def main():\n",
    "    # 从JSON文件加载数据\n",
    "    all_year_data = load_data_from_json(JSON_PATH)\n",
    "    if not all_year_data:\n",
    "        return\n",
    "    \n",
    "    # 生成汇总柱状图（至少2个年份才生成）\n",
    "    if len(all_year_data) >= 2:\n",
    "        generate_grouped_bar(all_year_data)\n",
    "    else:\n",
    "        print(\"❌ 年份数量不足，无法生成柱状图（至少需要2个年份）\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98b18a0-b858-41a7-8916-e873a62f91fe",
   "metadata": {},
   "source": [
    "3. Stream diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a897595e-b3fb-493e-ae6c-7c6576093854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 河流图已保存至：charts/keyword_stream.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import plotly.graph_objects as go\n",
    "from collections import defaultdict\n",
    "\n",
    "# --------------------- 配置区 ---------------------\n",
    "JSON_PATH = \"wordclouds/all_years_word_data.json\"  # 词频与颜色数据\n",
    "OUTPUT_DIR = \"charts\"                            # 河流图输出目录\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# 显示的关键词数量（控制河流图复杂度）\n",
    "TOP_N = 20  \n",
    "# 流量计算方式：'next'（用后一年频率）| 'mean'（两年均值）\n",
    "FLOW_METHOD = 'mean'  \n",
    "\n",
    "\n",
    "# --------------------- 辅助函数 ---------------------\n",
    "def hex_to_rgba(hex_color, alpha=0.5):\n",
    "    \"\"\"将十六进制颜色转换为带透明度的rgba格式\"\"\"\n",
    "    hex_color = hex_color.lstrip('#')\n",
    "    r = int(hex_color[0:2], 16)\n",
    "    g = int(hex_color[2:4], 16)\n",
    "    b = int(hex_color[4:6], 16)\n",
    "    return f'rgba({r}, {g}, {b}, {alpha})'\n",
    "\n",
    "\n",
    "# --------------------- 数据处理函数 ---------------------\n",
    "def load_data():\n",
    "    \"\"\"加载JSON数据并提取词频、颜色映射和年份列表\"\"\"\n",
    "    if not os.path.exists(JSON_PATH):\n",
    "        raise FileNotFoundError(f\"JSON文件不存在：{JSON_PATH}\")\n",
    "    \n",
    "    with open(JSON_PATH, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # 整理为 {年份: {词: 频率}} 格式\n",
    "    year_freq = {}\n",
    "    word_color = {}  # 全局词-颜色映射\n",
    "    for item in data:\n",
    "        year = item['year']\n",
    "        year_freq[year] = item['word_frequencies']\n",
    "        # 提取颜色映射（确保同词同色）\n",
    "        for word, color in item['word_colors'].items():\n",
    "            if word not in word_color:\n",
    "                word_color[word] = color\n",
    "    \n",
    "    # 按年份排序\n",
    "    sorted_years = sorted(year_freq.keys())\n",
    "    return year_freq, word_color, sorted_years\n",
    "\n",
    "\n",
    "def prepare_stream_data(year_freq, word_color, sorted_years):\n",
    "    \"\"\"准备河流图所需的数据流\"\"\"\n",
    "    # 1. 筛选高频关键词（跨年份总频率前TOP_N）\n",
    "    word_total = defaultdict(int)\n",
    "    for year, freq in year_freq.items():\n",
    "        for word, count in freq.items():\n",
    "            word_total[word] += count\n",
    "    top_words = [w for w, _ in sorted(word_total.items(), key=lambda x: x[1], reverse=True)[:TOP_N]]\n",
    "    \n",
    "    # 2. 构建数据流\n",
    "    stream_data = []\n",
    "    for word in top_words:\n",
    "        values = []\n",
    "        for year in sorted_years:\n",
    "            values.append(year_freq[year].get(word, 0))\n",
    "        stream_data.append({\n",
    "            \"name\": word,\n",
    "            \"values\": values,\n",
    "            \"color\": word_color.get(word, \"gray\")  # 复用词云颜色\n",
    "        })\n",
    "    \n",
    "    return stream_data, sorted_years\n",
    "\n",
    "\n",
    "# --------------------- 河流图绘制函数 ---------------------\n",
    "def generate_stream(stream_data, sorted_years):\n",
    "    \"\"\"生成河流图（含交互式标签、年份标注、统一色彩）\"\"\"\n",
    "    # 提取数据\n",
    "    labels = [data[\"name\"] for data in stream_data]\n",
    "    colors = [data[\"color\"] for data in stream_data]\n",
    "    values = [data[\"values\"] for data in stream_data]\n",
    "    \n",
    "    # 创建河流图数据\n",
    "    stream_data = go.Figure()\n",
    "    for i in range(len(labels)):\n",
    "        stream_data.add_trace(go.Scatter(\n",
    "            x=sorted_years,\n",
    "            y=values[i],\n",
    "            stackgroup=\"one\",  # 堆叠在同一组\n",
    "            groupnorm=\"percent\",  # 百分比堆叠\n",
    "            name=labels[i],\n",
    "            line=dict(color=colors[i], width=0.5),\n",
    "            fillcolor=hex_to_rgba(colors[i], 0.5)  # 填充颜色带透明度\n",
    "        ))\n",
    "    \n",
    "    # 设置布局（标题、尺寸等）\n",
    "    stream_data.update_layout(\n",
    "        title=dict(\n",
    "            text=f\"Keyword Frequency Stream ({sorted_years[0]} to {sorted_years[-1]})\",\n",
    "            font=dict(family=\"Arial\", size=16)\n",
    "        ),\n",
    "        width=1000,\n",
    "        height=800,\n",
    "        xaxis=dict(\n",
    "            title=\"Year\",\n",
    "            tickvals=sorted_years,\n",
    "            ticktext=[str(year) for year in sorted_years]\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=\"Percentage of Total Frequency\",\n",
    "            ticksuffix=\"%\"\n",
    "        ),\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.02,\n",
    "            xanchor=\"right\",\n",
    "            x=1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # 生成图表并保存\n",
    "    output_path = os.path.join(OUTPUT_DIR, \"keyword_stream.html\")\n",
    "    stream_data.write_html(output_path)\n",
    "    print(f\"✅ 河流图已保存至：{output_path}\")\n",
    "\n",
    "\n",
    "# --------------------- 主逻辑 ---------------------\n",
    "def main():\n",
    "    try:\n",
    "        # 加载数据\n",
    "        year_freq, word_color, sorted_years = load_data()\n",
    "        if len(sorted_years) < 2:\n",
    "            print(\"❌ 年份不足（至少需要2年数据），无法生成河流图\")\n",
    "            return\n",
    "        \n",
    "        # 准备河流图数据\n",
    "        stream_data, sorted_years = prepare_stream_data(year_freq, word_color, sorted_years)\n",
    "        if not stream_data:\n",
    "            print(\"❌ 未找到有效数据，无法生成河流图\")\n",
    "            return\n",
    "        \n",
    "        # 生成河流图\n",
    "        generate_stream(stream_data, sorted_years)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 错误：{str(e)}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ff8478-67a3-4ec7-b399-5b4f823b031b",
   "metadata": {},
   "source": [
    "4. Sankey diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c621b2a1-edd4-40fd-971c-fda7192a4156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 桑基图已保存至：charts/keyword_sankey.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import plotly.graph_objects as go\n",
    "from collections import defaultdict\n",
    "\n",
    "# --------------------- 配置区 ---------------------\n",
    "JSON_PATH = \"wordclouds/all_years_word_data.json\"  # 词频与颜色数据\n",
    "OUTPUT_DIR = \"charts\"                            # 桑基图输出目录\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# 显示的关键词数量（控制桑基图复杂度）\n",
    "TOP_N = 20  \n",
    "# 流量计算方式：'next'（用后一年频率）| 'mean'（两年均值）\n",
    "FLOW_METHOD = 'mean'  \n",
    "\n",
    "\n",
    "# --------------------- 辅助函数 ---------------------\n",
    "def hex_to_rgba(hex_color, alpha=0.5):\n",
    "    \"\"\"将十六进制颜色转换为带透明度的rgba格式\"\"\"\n",
    "    hex_color = hex_color.lstrip('#')\n",
    "    r = int(hex_color[0:2], 16)\n",
    "    g = int(hex_color[2:4], 16)\n",
    "    b = int(hex_color[4:6], 16)\n",
    "    return f'rgba({r}, {g}, {b}, {alpha})'\n",
    "\n",
    "\n",
    "# --------------------- 数据处理函数 ---------------------\n",
    "def load_data():\n",
    "    \"\"\"加载JSON数据并提取词频、颜色映射和年份列表\"\"\"\n",
    "    if not os.path.exists(JSON_PATH):\n",
    "        raise FileNotFoundError(f\"JSON文件不存在：{JSON_PATH}\")\n",
    "    \n",
    "    with open(JSON_PATH, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # 整理为 {年份: {词: 频率}} 格式\n",
    "    year_freq = {}\n",
    "    word_color = {}  # 全局词-颜色映射\n",
    "    for item in data:\n",
    "        year = item['year']\n",
    "        year_freq[year] = item['word_frequencies']\n",
    "        # 提取颜色映射（确保同词同色）\n",
    "        for word, color in item['word_colors'].items():\n",
    "            if word not in word_color:\n",
    "                word_color[word] = color\n",
    "    \n",
    "    # 按年份排序\n",
    "    sorted_years = sorted(year_freq.keys())\n",
    "    return year_freq, word_color, sorted_years\n",
    "\n",
    "\n",
    "def prepare_sankey_data(year_freq, word_color, sorted_years):\n",
    "    \"\"\"准备桑基图所需的节点（nodes）和链接（links）数据\"\"\"\n",
    "    # 1. 筛选高频关键词（跨年份总频率前TOP_N）\n",
    "    word_total = defaultdict(int)\n",
    "    for year, freq in year_freq.items():\n",
    "        for word, count in freq.items():\n",
    "            word_total[word] += count\n",
    "    top_words = [w for w, _ in sorted(word_total.items(), key=lambda x: x[1], reverse=True)[:TOP_N]]\n",
    "    \n",
    "    # 2. 构建节点：每个关键词为一个节点（含颜色）\n",
    "    nodes = []\n",
    "    word_id = {word: i for i, word in enumerate(top_words)}  # 关键词到id的映射\n",
    "    for word in top_words:\n",
    "        nodes.append({\n",
    "            \"name\": word,\n",
    "            \"color\": word_color.get(word, \"gray\")  # 复用词云颜色\n",
    "        })\n",
    "    \n",
    "    # 3. 构建链接：相邻年份同一关键词的频率流动\n",
    "    links = []\n",
    "    for i in range(len(sorted_years) - 1):\n",
    "        year1 = sorted_years[i]\n",
    "        year2 = sorted_years[i + 1]\n",
    "        freq1 = year_freq[year1]\n",
    "        freq2 = year_freq[year2]\n",
    "        \n",
    "        # 只处理TOP关键词之间的链接\n",
    "        for word in top_words:\n",
    "            count1 = freq1.get(word, 0)\n",
    "            count2 = freq2.get(word, 0)\n",
    "            if count1 == 0 or count2 == 0:\n",
    "                continue  # 跳过无频率的关键词\n",
    "            \n",
    "            # 计算流量值（根据设定的方法）\n",
    "            if FLOW_METHOD == 'mean':\n",
    "                value = int((count1 + count2) / 2)\n",
    "            else:  # 'next'\n",
    "                value = count2\n",
    "            \n",
    "            # 转换颜色格式为rgba（解决Plotly不支持8位十六进制的问题）\n",
    "            link_color = hex_to_rgba(word_color.get(word, '#999999'), 0.5)\n",
    "            \n",
    "            # 添加链接（源为year1的词id，目标为year2的词id）\n",
    "            links.append({\n",
    "                \"source\": word_id[word],\n",
    "                \"target\": word_id[word],  # 同一关键词流动\n",
    "                \"value\": value,\n",
    "                \"color\": link_color\n",
    "            })\n",
    "    \n",
    "    return nodes, links, top_words\n",
    "\n",
    "\n",
    "# --------------------- 桑基图绘制函数 ---------------------\n",
    "def generate_sankey(nodes, links, top_words, sorted_years):\n",
    "    \"\"\"生成桑基图（含交互式标签、年份标注、统一色彩）\"\"\"\n",
    "    # 提取节点颜色和名称\n",
    "    node_colors = [node[\"color\"] for node in nodes]\n",
    "    node_labels = [node[\"name\"] for node in nodes]\n",
    "    \n",
    "    # 提取链接数据\n",
    "    source = [link[\"source\"] for link in links]\n",
    "    target = [link[\"target\"] for link in links]\n",
    "    value = [link[\"value\"] for link in links]\n",
    "    link_colors = [link[\"color\"] for link in links]\n",
    "    \n",
    "    # 创建桑基图数据\n",
    "    sankey_data = go.Sankey(\n",
    "        node=dict(\n",
    "            pad=15,  # 节点间距\n",
    "            thickness=20,  # 节点厚度\n",
    "            line=dict(color=\"black\", width=0.5),  # 节点边框\n",
    "            color=node_colors,\n",
    "            label=node_labels\n",
    "        ),\n",
    "        link=dict(\n",
    "            source=source,\n",
    "            target=target,\n",
    "            value=value,\n",
    "            color=link_colors  # 使用rgba格式的颜色\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # 设置布局（标题、尺寸等）\n",
    "    layout = go.Layout(\n",
    "        title=dict(\n",
    "            text=f\"Keyword Frequency Flow ({sorted_years[0]} to {sorted_years[-1]})\",\n",
    "            font=dict(family=\"Arial\", size=16)\n",
    "        ),\n",
    "        width=1000,\n",
    "        height=800,\n",
    "        margin=dict(l=50, r=50, t=100, b=50)\n",
    "    )\n",
    "    \n",
    "    # 生成图表并保存\n",
    "    fig = go.Figure(data=[sankey_data], layout=layout)\n",
    "    output_path = os.path.join(OUTPUT_DIR, \"keyword_sankey1.html\")\n",
    "    fig.write_html(output_path)\n",
    "    print(f\"✅ 桑基图已保存至：{output_path}\")\n",
    "\n",
    "\n",
    "# --------------------- 主逻辑 ---------------------\n",
    "def main():\n",
    "    try:\n",
    "        # 加载数据\n",
    "        year_freq, word_color, sorted_years = load_data()\n",
    "        if len(sorted_years) < 2:\n",
    "            print(\"❌ 年份不足（至少需要2年数据），无法生成桑基图\")\n",
    "            return\n",
    "        \n",
    "        # 准备桑基图数据\n",
    "        nodes, links, top_words = prepare_sankey_data(year_freq, word_color, sorted_years)\n",
    "        if not links:\n",
    "            print(\"❌ 未找到有效链接数据，无法生成桑基图\")\n",
    "            return\n",
    "        \n",
    "        # 生成桑基图\n",
    "        generate_sankey(nodes, links, top_words, sorted_years)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 错误：{str(e)}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
