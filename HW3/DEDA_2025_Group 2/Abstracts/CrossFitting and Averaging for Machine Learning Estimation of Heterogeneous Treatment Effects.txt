Abstract:We investigate the finite sample performance of sample splitting, cross-fittingand averaging for the estimation of the conditional average treatment effect.Recently proposed methods, so-called meta- learners, make use of machinelearning to estimate different nuisance functions and hence allow for fewerrestrictions on the underlying structure of the data. To limit a potentialoverfitting bias that may result when using machine learning methods, cross-fitting estimators have been proposed. This includes the splitting of the datain different folds to reduce bias and averaging over folds to restoreefficiency. To the best of our knowledge, it is not yet clear how exactly thedata should be split and averaged. We employ a Monte Carlo study with differentdata generation processes and consider twelve different estimators that vary insample-splitting, cross-fitting and averaging procedures. We investigate theperformance of each estimator independently on four different meta-learners: thedoubly-robust-learner, R-learner, T-learner and X-learner. We find that theperformance of all meta-learners heavily depends on the procedure of splittingand averaging. The best performance in terms of mean squared error (MSE) amongthe sample split estimators can be achieved when applying cross-fitting plustaking the median over multiple different sample-splitting iterations. Somemeta-learners exhibit a high variance when the lasso is included in the MLmethods. Excluding the lasso decreases the variance and leads to robust and atleast competitive results.Keywords:causal inference, sample splitting, cross-fitting, sample averaging, machinelearning, simulation study